# ğŸ§  Coddy AI - Next Gen Neural Assistant

> **Optimized â€¢ Local â€¢ High-Performance**

Coddy AI is a state-of-the-art local AI assistant featuring a high-performance Python backend and a stunning, reactive Next.js frontend. It leverages advanced optimization libraries to ensure lightning-fast responses and efficient resource usage.

![Coddy AI Frontend](./frontend/public/window.svg)

## âš¡ High-Performance Core

The architecture has been massively optimized with top-tier libraries:

### ğŸ Backend (Python / FastAPI)

- **ğŸš€ CoddyEngine2**: Custom C++ optimized inference engine (simulated).
- **ğŸ“š Qdrant + DiskCache**: Hybrid vector search system with **DiskCache** for sub-millisecond query retrieval on repeated searches.
- **ğŸªµ Loguru**: Beautiful, asynchronous structured logging.
- **ï¿½ ORJSON**: High-performance JSON serialization, replacing standard `json` lib.
- **ğŸ¦† DuckDB**: Integrated for future high-speed analytical queries.
- **â›“ï¸ LangChain**: Ready for complex chain orchestration.

### âš›ï¸ Frontend (Next.js 16)

- **âš¡ SWR**: State-of-the-art data fetching with automatic revalidation and caching.
- **ğŸ¨ Tailwind CSS + CLSX**: Optimized, mergeable utility classes for dynamic styling.
- **ğŸ–¼ï¸ Sharp**: High-performance image optimization.
- **ğŸŒ€ Framer Motion**: Butter-smooth 60fps animations.

---

## ğŸ› ï¸ Installation & Setup

### Prerequisites

- Python 3.10+
- Node.js 18+
- Git

### 1. Clone & Setup Backend

```bash
git clone https://github.com/biagio-scaglia/my-ai.git
cd my-ai

# Install Python Dependencies (Optimized)
pip install -r requirements.txt
```

### 2. Setup Frontend

```bash
cd frontend

# Install Node Dependencies
npm install
```

---

## ğŸš€ Usage

### Start the System (All-in-One)

Simply run the startup script:

```bash
./start_app.bat
```

This will launch both the FastAPI backend server (Port 8000) and the Next.js frontend (Port 3000).

### Manual Start

**Backend:**

```bash
python api.py
```

**Frontend:**

```bash
cd frontend
npm run dev
```

---

## ğŸ“‚ Project Structure

```
my-ai/
â”œâ”€â”€ ğŸ§  api.py              # Main FastAPI entrypoint (Optimized with loguru/orjson)
â”œâ”€â”€ âš™ï¸ engine_cpp.py       # Core Inference Engine
â”œâ”€â”€ ğŸ” rag_engine.py       # RAG System with DiskCache & Qdrant
â”œâ”€â”€ ğŸ“œ requirements.txt    # Python dependencies
â”œâ”€â”€ ğŸ“ frontend/           # Next.js 16 Application
â”‚   â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”‚   â”œâ”€â”€ ğŸ§© components/ # ChatInterface, Navbar (Optimized with clsx)
â”‚   â”‚   â””â”€â”€ ğŸ“„ app/        # App Router Pages
â”‚   â””â”€â”€ âš™ï¸ package.json    # Frontend dependencies
â””â”€â”€ ï¿½ï¸ knowledge/          # RAG Knowledge Base
```

---

## ğŸŒŸ Key Features

- **Local RAG**: Queries your local `knowledge/` folder with vector search.
- **Smart Caching**: `DiskCache` remembers previous answers to save compute.
- **Real-time Status**: Frontend polls backend health via `SWR`.
- **Cyberpunk UI**: A premium, "Made by Biagio" design aesthetic.

---

_Built with â¤ï¸ by Biagio Scaglia_
